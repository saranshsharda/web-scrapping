{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main Page</td>\n",
       "      <td>From today's featured article</td>\n",
       "      <td>Languages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Did you know ...</td>\n",
       "      <td>Personal tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>In the news</td>\n",
       "      <td>Namespaces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>On this day</td>\n",
       "      <td>Variants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>From today's featured list</td>\n",
       "      <td>Views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>Today's featured picture</td>\n",
       "      <td>More</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "      <td>Navigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "      <td>Contribute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>Wikipedia languages</td>\n",
       "      <td>Tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>Navigation menu</td>\n",
       "      <td>Print/export</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>In other projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           h1                             h2                 h3\n",
       "0   Main Page  From today's featured article          Languages\n",
       "1        None               Did you know ...     Personal tools\n",
       "2        None                    In the news         Namespaces\n",
       "3        None                    On this day           Variants\n",
       "4        None     From today's featured list              Views\n",
       "5        None       Today's featured picture               More\n",
       "6        None       Other areas of Wikipedia         Navigation\n",
       "7        None    Wikipedia's sister projects         Contribute\n",
       "8        None            Wikipedia languages              Tools\n",
       "9        None                Navigation menu       Print/export\n",
       "10       None                           None  In other projects\n",
       "11       None                           None          Languages"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from lxml import html\n",
    "\n",
    "wikipageContent=requests.get(\n",
    "     'https://en.wikipedia.org/wiki/Main_Page'\n",
    ")\n",
    "\n",
    "tree = html.fromstring(wikipageContent.content)\n",
    "\n",
    "_to_scrape = ['h1','h2','h3']\n",
    "l1,l2,l3 = [],[],[]\n",
    "while True:\n",
    "\n",
    "    for element in _to_scrape:\n",
    "        path = f'//{element}'\n",
    "        for j in range(len(tree.xpath(path))):\n",
    "            if element == 'h1':\n",
    "                l1.append(tree.xpath(path)[j].text_content())\n",
    "            elif element == 'h2':\n",
    "                l2.append(tree.xpath(path)[j].text_content())\n",
    "            else:\n",
    "                custom_path = path + '/span'\n",
    "                l3.append(tree.xpath(custom_path)[j-1].text_content())  \n",
    "    break\n",
    "\n",
    "dict = {'h1':l1,'h2':l2,'h3':l3}\n",
    "wiki_header_df = pd.DataFrame.from_dict(dict, orient='index').T\n",
    "wiki_header_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and save it in form of a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>movie_imdb_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>(1972)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>(1974)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>(1957)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>(1959)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>(1971)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Snatch</td>\n",
       "      <td>(2000)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Amélie</td>\n",
       "      <td>(2001)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Kid</td>\n",
       "      <td>(1921)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  movie_name movie_year movie_imdb_rating\n",
       "0   The Shawshank Redemption     (1994)               9.3\n",
       "1              The Godfather     (1972)               9.2\n",
       "2     The Godfather: Part II     (1974)                 9\n",
       "3            The Dark Knight     (2008)                 9\n",
       "4               12 Angry Men     (1957)                 9\n",
       "..                       ...        ...               ...\n",
       "95        North by Northwest     (1959)               8.3\n",
       "96        A Clockwork Orange     (1971)               8.3\n",
       "97                    Snatch     (2000)               8.3\n",
       "98                    Amélie     (2001)               8.3\n",
       "99                   The Kid     (1921)               8.3\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "url = 'https://www.imdb.com/list/ls091520106/'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "sauce = urllib.request.urlopen(url).read()\n",
    "\n",
    "soup = BeautifulSoup(sauce,'html.parser')\n",
    "\n",
    "\n",
    "blocks = soup.find_all('h3',attrs={'class':'lister-item-header'})          # for scraping the name and the relase year of the movie\n",
    "rating_blocks = soup.find_all('div',attrs={'class':'ipl-rating-widget'})   # for scraping the ratings of the movie\n",
    "\n",
    "assert len(blocks) == len(rating_blocks)                                   # sanity check\n",
    "\n",
    "m_name,m_year,m_rating = [],[],[]                                         \n",
    "\n",
    "for block in blocks:\n",
    "    #print(block.a.text)\n",
    "    m_name.append(block.a.text)                                                            # --> Add movie names a list\n",
    "    #print(block.find('span', class_ = 'lister-item-year text-muted unbold').text)\n",
    "    m_year.append(block.find('span', class_ = 'lister-item-year text-muted unbold').text)  # --> Add movie release year to a list   \n",
    "\n",
    "    \n",
    "for r_block in rating_blocks:\n",
    "    #print(r_block.find('span', class_ = 'ipl-rating-star__rating').text)\n",
    "    m_rating.append(r_block.find('span', class_ = 'ipl-rating-star__rating').text)         # --> Add ratings to a list\n",
    "    \n",
    "imdb_top100_df = pd.DataFrame({'movie_name':m_name,'movie_year':m_year,'movie_imdb_rating':m_rating})  # --> creating a dataframe\n",
    "\n",
    "imdb_top100_df.to_csv('imdb_top100_movies.csv',index=False)\n",
    "\n",
    "imdb_top100_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and save it in form of a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>movie_imdb_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pather Panchali</td>\n",
       "      <td>(1955)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gol Maal</td>\n",
       "      <td>(1979)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>(1987)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>(2003)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apur Sansar</td>\n",
       "      <td>(1959)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>The Legend of Bhagat Singh</td>\n",
       "      <td>(2002)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Barfi!</td>\n",
       "      <td>(2012)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Pink</td>\n",
       "      <td>(2016)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bommarillu</td>\n",
       "      <td>(2006)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bombay</td>\n",
       "      <td>(1995)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    movie_name movie_year movie_imdb_rating\n",
       "0              Pather Panchali     (1955)               8.5\n",
       "1                     Gol Maal     (1979)               8.5\n",
       "2                      Nayakan     (1987)               8.5\n",
       "3                   Anbe Sivam     (2003)               8.5\n",
       "4                  Apur Sansar     (1959)               8.5\n",
       "..                         ...        ...               ...\n",
       "95  The Legend of Bhagat Singh     (2002)               8.0\n",
       "96                      Barfi!     (2012)               8.0\n",
       "97                        Pink     (2016)               8.0\n",
       "98                  Bommarillu     (2006)               8.0\n",
       "99                      Bombay     (1995)               8.0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "url = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "sauce = urllib.request.urlopen(url).read()\n",
    "\n",
    "soup = BeautifulSoup(sauce,'html.parser')\n",
    "\n",
    "\n",
    "blocks = soup.find_all('td',attrs={'class':'titleColumn'})        \n",
    "rating_blocks = rating_block = soup.find_all('strong')             \n",
    "\n",
    "assert len(blocks) == len(rating_blocks)                           \n",
    "\n",
    "m_name,m_year,m_rating = [],[],[]                                         \n",
    "\n",
    "for block in blocks[:100]:\n",
    "    m_name.append(block.a.text)                                  \n",
    "    m_year.append(block.span.text)                               \n",
    "\n",
    "    \n",
    "for r_block in rating_blocks[:100]:\n",
    "    m_rating.append(r_block.text)                             \n",
    "    \n",
    "\n",
    "imdb_top100_indian_df = pd.DataFrame({'movie_name':m_name,'movie_year':m_year,'movie_imdb_rating':m_rating})  # --> creating a dataframe\n",
    "\n",
    "imdb_top100_indian_df.to_csv('imdb_top100_indian_movies.csv',index=False)\n",
    "\n",
    "imdb_top100_indian_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrap book name, author name, genre and book review of any 5 books from ‘www.bookpage.com’\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_name</th>\n",
       "      <th>genres</th>\n",
       "      <th>author_name</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>★ Secrets of Happiness</td>\n",
       "      <td>[Fiction, Family Drama]</td>\n",
       "      <td>Joan Silber</td>\n",
       "      <td>The challenges of balancing money and personal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Olympus, Texas</td>\n",
       "      <td>[Fiction, Family Drama]</td>\n",
       "      <td>Stacey Swann</td>\n",
       "      <td>J.R. Ewing, the man everyone loves to hate in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From Little Tokyo, With Love</td>\n",
       "      <td>[YA, YA Fiction]</td>\n",
       "      <td>Sarah Kuhn</td>\n",
       "      <td>Rika Rakuyama loves Little Tokyo, from its ram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seed to Dust</td>\n",
       "      <td>[Nonfiction, Memoir, Nature]</td>\n",
       "      <td>Marc Hamer</td>\n",
       "      <td>To whom does a garden belong? In his work as a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Before I Saw You</td>\n",
       "      <td>[Romance, Contemporary Romance]</td>\n",
       "      <td>Emily Houghton</td>\n",
       "      <td>Emily Houghton’s Before I Saw You is a tender,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      book_name                           genres  \\\n",
       "0        ★ Secrets of Happiness          [Fiction, Family Drama]   \n",
       "1                Olympus, Texas          [Fiction, Family Drama]   \n",
       "2  From Little Tokyo, With Love                 [YA, YA Fiction]   \n",
       "3                  Seed to Dust     [Nonfiction, Memoir, Nature]   \n",
       "4              Before I Saw You  [Romance, Contemporary Romance]   \n",
       "\n",
       "      author_name                                             review  \n",
       "0     Joan Silber  The challenges of balancing money and personal...  \n",
       "1    Stacey Swann  J.R. Ewing, the man everyone loves to hate in ...  \n",
       "2      Sarah Kuhn  Rika Rakuyama loves Little Tokyo, from its ram...  \n",
       "3      Marc Hamer  To whom does a garden belong? In his work as a...  \n",
       "4  Emily Houghton  Emily Houghton’s Before I Saw You is a tender,...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "main_url = 'https://bookpage.com/reviews'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "sauce = urllib.request.urlopen(main_url).read()\n",
    "\n",
    "soup = BeautifulSoup(sauce,'html.parser')\n",
    "\n",
    "\n",
    "title_block = soup.find_all('div',attrs={'class':'row-fluid article-row'})\n",
    "author_block = soup.find_all('p',attrs={'class':'sans bold'})\n",
    "url_block = soup.find_all('div',attrs={'class':'read-full'})\n",
    "\n",
    "l1,l2,l3,l4 = [],[],[],[]\n",
    "\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    for t in title_block[:5]:\n",
    "        l1.append(t.find_all('a')[1].text)\n",
    "\n",
    "    for genre in title_block[:5]:\n",
    "        temp = []\n",
    "        all_genres_per_book = genre.find_all('a')[2:-1]\n",
    "        for all_g in all_genres_per_book:\n",
    "            temp.append(all_g.text)\n",
    "        l2.append(temp)\n",
    "        \n",
    "    for a in author_block[:5]:\n",
    "        l3.append(a.text.strip('\\n'))\n",
    "\n",
    "    for url in url_block[:5]:\n",
    "        url_review = main_url.strip('/reviews') + url.a.get('href')\n",
    "\n",
    "        sauce_2 = urllib.request.urlopen(url_review).read()\n",
    "        soup_2 = BeautifulSoup(sauce_2,'html.parser')\n",
    "\n",
    "        l4.append(soup_2.find('div',attrs={'class':'article-body'}).text.strip('\\n'))\n",
    "            \n",
    "    book_review_df = pd.DataFrame({'book_name': l1,'genres':l2,'author_name':l3,'review':l4})\n",
    "    \n",
    "    return book_review_df\n",
    "        \n",
    "\n",
    "        \n",
    "df = get_data()\n",
    "\n",
    "df.to_json('book_review.json',orient='records')\n",
    "df.to_csv('book_review.csv',index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "# Top 10 ODI teams in men’s cricket along with the records for matches, points and rating. \n",
    "# Top 10 ODI Batsmen in men along with the records of their team and rating. \n",
    "#Top 10 ODI bowlers along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 11001] getaddrinfo failed>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[0;32m   1351\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1254\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1300\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    949\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1417\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    920\u001b[0m         \u001b[1;34m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m         self.sock = self._create_connection(\n\u001b[0m\u001b[0;32m    922\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    786\u001b[0m     \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    917\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-4a4c819516e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m }\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0msauce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msauce\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'urllib.Request'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[0;32m    543\u001b[0m                                   '_open', req)\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1392\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1393\u001b[1;33m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[0;32m   1394\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1351\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0;32m   1352\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1353\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1354\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [Errno 11001] getaddrinfo failed>"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "sauce = urllib.request.urlopen(url).read()\n",
    "\n",
    "soup = BeautifulSoup(sauce,'html.parser')\n",
    "\n",
    "c_name = []\n",
    "match_number = []\n",
    "points = []\n",
    "rating = []\n",
    "\n",
    "\n",
    "c_1_name = soup.find('span',attrs={'class':'u-hide-phablet'})\n",
    "c_1_ranking_ = soup.find('td',attrs={'class':'rankings-block__banner--rating'})\n",
    "c_1_match_ = soup.find('td',attrs={'class':'rankings-block__banner--matches'})\n",
    "c_1_points_ = soup.find('td',attrs={'class':'rankings-block__banner--points'})\n",
    "\n",
    "c_name.append(c_1_name.find('div',class_ = \"u-hide-phablet\").text)\n",
    "match_number.append(c_1_match__.text)\n",
    "rating.append(c_1_ranking_.text)\n",
    "points.append(c_1_points_.text)\n",
    "\n",
    "table_rows = soup.find_all('tr',attrs={'class':'table-body'})\n",
    "\n",
    "for row in table_rows[:10]:\n",
    "    \n",
    "    c_name_number.append(row.find('td',class_=\"table-body__cell rankings-table__team\").text)\n",
    "    match_number.append(row.find('td',class_=\"table-body__cell u-center-text\").text)\n",
    "    rating.append(row.find('td',class_ =\"table-body__cell u-text-right rating\").text)\n",
    "    points.append(row.find('td',class_ =\"table-body__cell u-center-text\").text)\n",
    "\n",
    "df_odi_teams = pd.DataFrame({'country_name': c_name,'matches':match_number,'ranking': rating,'points': points})\n",
    "\n",
    "df_odi_teams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>country</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Francois du Plessis</td>\n",
       "      <td>SA</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            player_name country ranking\n",
       "0            Babar Azam     865     865\n",
       "1           Virat Kohli     IND     857\n",
       "2          Rohit Sharma     IND     825\n",
       "3           Ross Taylor      NZ     801\n",
       "4           Aaron Finch     AUS     791\n",
       "5        Jonny Bairstow     ENG     785\n",
       "6          Fakhar Zaman     PAK     778\n",
       "7   Francois du Plessis      SA     778\n",
       "8          David Warner     AUS     773\n",
       "9             Shai Hope      WI     773\n",
       "10      Quinton de Kock      SA     756"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "sauce = urllib.request.urlopen(url).read()\n",
    "\n",
    "soup = BeautifulSoup(sauce,'html.parser')\n",
    "\n",
    "p_name = []\n",
    "country_name = []\n",
    "rating = []\n",
    "\n",
    "\n",
    "# for the player in the banner ( No 1 player)\n",
    "player_1_block = soup.find('tr',attrs={'class':'rankings-block__banner'})\n",
    "player_1_block_ranking_ = soup.find('div',attrs={'class':'rankings-block__banner--rating'}) \n",
    "\n",
    "p_name.append(player_1_block.find('div',class_ = \"rankings-block__banner--name-large\").text)\n",
    "country_name.append(player_1_block.find_all('div')[-2].text.strip('\\n'))\n",
    "rating.append(player_1_block_ranking_.text)\n",
    "\n",
    "table_rows = soup.find_all('tr',attrs={'class':'table-body'})\n",
    "\n",
    "for row in table_rows[:10]:\n",
    "    p_name.append(row.find('a').text)\n",
    "    country_name.append(row.find('span',class_=\"table-body__logo-text\").text)\n",
    "    rating.append(row.find('td',class_ =\"table-body__cell rating\").text)\n",
    "\n",
    "df_mens_odi_players = pd.DataFrame({'player_name': p_name,'country':country_name,'ranking': rating})\n",
    "\n",
    "df_mens_odi_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>country</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>737</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pat Cummins</td>\n",
       "      <td>AUS</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mohammad Amir</td>\n",
       "      <td>PAK</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         player_name country ranking\n",
       "0        Trent Boult     737     737\n",
       "1   Mujeeb Ur Rahman     AFG     708\n",
       "2         Matt Henry      NZ     691\n",
       "3     Jasprit Bumrah     IND     690\n",
       "4       Mehedi Hasan     BAN     668\n",
       "5      Kagiso Rabada      SA     666\n",
       "6       Chris Woakes     ENG     665\n",
       "7     Josh Hazlewood     AUS     660\n",
       "8        Pat Cummins     AUS     646\n",
       "9      Mohammad Amir     PAK     638\n",
       "10    Shaheen Afridi     PAK     634"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "sauce = urllib.request.urlopen(url).read()\n",
    "\n",
    "soup = BeautifulSoup(sauce,'html.parser')\n",
    "\n",
    "p_name = []\n",
    "country_name = []\n",
    "rating = []\n",
    "\n",
    "\n",
    "# for the player in the banner ( No 1 player)\n",
    "player_1_block = soup.find('tr',attrs={'class':'rankings-block__banner'})\n",
    "player_1_block_ranking_ = soup.find('div',attrs={'class':'rankings-block__banner--rating'}) \n",
    "\n",
    "p_name.append(player_1_block.find('div',class_ = \"rankings-block__banner--name-large\").text)\n",
    "country_name.append(player_1_block.find_all('div')[-2].text.strip('\\n'))\n",
    "rating.append(player_1_block_ranking_.text)\n",
    "\n",
    "table_rows = soup.find_all('tr',attrs={'class':'table-body'})\n",
    "\n",
    "for row in table_rows[:10]:\n",
    "    p_name.append(row.find('a').text)\n",
    "    country_name.append(row.find('span',class_=\"table-body__logo-text\").text)\n",
    "    rating.append(row.find('td',class_ =\"table-body__cell rating\").text)\n",
    "\n",
    "df_mens_odi_players = pd.DataFrame({'player_name': p_name,'country':country_name,'ranking': rating})\n",
    "\n",
    "df_mens_odi_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "# Top 10 ODI teams in women’s cricket along with the records for matches, points and rating. \n",
    "# Top 10 women’s ODI players along with the records of their team and rating. \n",
    "#Top 10 women’s ODI all-rounder along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-c19cbb9b6566>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mcountry_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer_1_block\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mrating\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer_1_block_ranking_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[0mpoint_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer_1_block_match_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mmatch_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer_1_block_point_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "sauce = urllib.request.urlopen(url).read()\n",
    "\n",
    "soup = BeautifulSoup(sauce,'html.parser')\n",
    "\n",
    "country_name = []\n",
    "match_name = []\n",
    "point_name = []\n",
    "rating = []\n",
    "\n",
    "\n",
    "# for the player in the banner ( No 1 player)\n",
    "player_1_block = soup.find('span',attrs={'class':'u-hide-phablet'})\n",
    "player_1_block_ranking_ = soup.find('div',attrs={'class':'rankings-block__banner--rating u-text-right'}) \n",
    "player_1_block_match_ = soup.find('td',attrs={'class':'rankings-block__banner--matches'}) \n",
    "player_1_block_point_ = soup.find('td',attrs={'class':'rankings-block__banner--points'}) \n",
    "\n",
    "country_name.append(player_1_block.text)\n",
    "rating.append(player_1_block_ranking_.text)\n",
    "point_name.append(player_1_block_match_.text)\n",
    "match_name.append(player_1_block_point_.text)\n",
    "\n",
    "table_rows = soup.find_all('tr',attrs={'class':'table-body'})\n",
    "\n",
    "for row in table_rows[:10]:\n",
    "    p_name.append(row.find('a').text)\n",
    "    country_name.append(row.find('span',class_=\"table-body__logo-text\").text)\n",
    "    rating.append(row.find('td',class_ =\"table-body__cell rating\").text)\n",
    "\n",
    "df_womens_odi_teams = pd.DataFrame({'country':country_name,'matches': match_name,'points': point_name,'ranking': rating})\n",
    "\n",
    "df_womens_odi_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>country</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>765</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          player_name country ranking\n",
       "0      Tammy Beaumont     765     765\n",
       "1         Lizelle Lee      SA     758\n",
       "2        Alyssa Healy     AUS     756\n",
       "3     Stafanie Taylor      WI     746\n",
       "4         Meg Lanning     AUS     723\n",
       "5   Amy Satterthwaite      NZ     715\n",
       "6     Smriti Mandhana     IND     710\n",
       "7         Mithali Raj     IND     709\n",
       "8      Natalie Sciver     ENG     685\n",
       "9     Laura Wolvaardt      SA     683\n",
       "10       Ellyse Perry     AUS     679"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "sauce = urllib.request.urlopen(url).read()\n",
    "\n",
    "soup = BeautifulSoup(sauce,'html.parser')\n",
    "\n",
    "p_name = []\n",
    "country_name = []\n",
    "rating = []\n",
    "\n",
    "\n",
    "# for the player in the banner ( No 1 player)\n",
    "player_1_block = soup.find('tr',attrs={'class':'rankings-block__banner'})\n",
    "player_1_block_ranking_ = soup.find('div',attrs={'class':'rankings-block__banner--rating'}) \n",
    "\n",
    "p_name.append(player_1_block.find('div',class_ = \"rankings-block__banner--name-large\").text)\n",
    "country_name.append(player_1_block.find_all('div')[-2].text.strip('\\n'))\n",
    "rating.append(player_1_block_ranking_.text)\n",
    "\n",
    "table_rows = soup.find_all('tr',attrs={'class':'table-body'})\n",
    "\n",
    "for row in table_rows[:10]:\n",
    "    p_name.append(row.find('a').text)\n",
    "    country_name.append(row.find('span',class_=\"table-body__logo-text\").text)\n",
    "    rating.append(row.find('td',class_ =\"table-body__cell rating\").text)\n",
    "\n",
    "df_womens_odi_players = pd.DataFrame({'player_name': p_name,'country':country_name,'ranking': rating})\n",
    "\n",
    "df_womens_odi_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>country</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>418</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         player_name country ranking\n",
       "0     Marizanne Kapp     418     418\n",
       "1       Ellyse Perry     AUS     418\n",
       "2    Stafanie Taylor      WI     410\n",
       "3     Natalie Sciver     ENG     349\n",
       "4      Deepti Sharma     IND     343\n",
       "5      Jess Jonassen     AUS     307\n",
       "6   Ashleigh Gardner     AUS     252\n",
       "7   Dane van Niekerk      SA     243\n",
       "8      Sophie Devine      NZ     242\n",
       "9        Amelia Kerr      NZ     236\n",
       "10   Katherine Brunt     ENG     236"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "sauce = urllib.request.urlopen(url).read()\n",
    "\n",
    "soup = BeautifulSoup(sauce,'html.parser')\n",
    "\n",
    "p_name = []\n",
    "country_name = []\n",
    "rating = []\n",
    "\n",
    "\n",
    "# for the player in the banner ( No 1 player)\n",
    "player_1_block = soup.find('tr',attrs={'class':'rankings-block__banner'})\n",
    "player_1_block_ranking_ = soup.find('div',attrs={'class':'rankings-block__banner--rating'}) \n",
    "\n",
    "p_name.append(player_1_block.find('div',class_ = \"rankings-block__banner--name-large\").text)\n",
    "country_name.append(player_1_block.find_all('div')[-2].text.strip('\\n'))\n",
    "rating.append(player_1_block_ranking_.text)\n",
    "\n",
    "table_rows = soup.find_all('tr',attrs={'class':'table-body'})\n",
    "\n",
    "for row in table_rows[:10]:\n",
    "    p_name.append(row.find('a').text)\n",
    "    country_name.append(row.find('span',class_=\"table-body__logo-text\").text)\n",
    "    rating.append(row.find('td',class_ =\"table-body__cell rating\").text)\n",
    "\n",
    "df_womens_odi_players = pd.DataFrame({'player_name': p_name,'country':country_name,'ranking': rating})\n",
    "\n",
    "df_womens_odi_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL \n",
    "and Average Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-e7cd6e07d9f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0ml2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mprice\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprice_block\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0ml3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimg_url\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'src'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg_url\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimg_url_block\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0ml4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrating\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrating\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mratings_block\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mamazon__under_20k_mobiles_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'mobile_name'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'price'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rating'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ml4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'image_url'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ml3\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-e7cd6e07d9f7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0ml2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mprice\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprice_block\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0ml3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimg_url\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'src'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg_url\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimg_url_block\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0ml4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrating\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrating\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mratings_block\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mamazon__under_20k_mobiles_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'mobile_name'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'price'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rating'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ml4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'image_url'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ml3\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "url = 'https://www.amazon.in/Mobile-Phone-Under-20000-Rupees/s?k=Mobile+Phone+Under+20000+Rupees'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "sauce = urllib.request.urlopen(url).read()\n",
    "\n",
    "soup = BeautifulSoup(sauce,'html.parser')\n",
    "\n",
    "\n",
    "name_block = soup.find_all('',attrs={'class' : 'a-size-medium a-color-base a-text-normal'})\n",
    "price_block =  soup.find_all('span',attrs={'class':'a-price-whole'})\n",
    "img_url_block = soup.find_all('div',attrs={'class':'a-section aok-relative s-image-fixed-height'})\n",
    "rating_block = soup.find_all('span',attrs={'class':'a-icon-alt'})\n",
    "\n",
    "Rating=[]\n",
    "\n",
    "for i in rating:\n",
    "\n",
    "    Rating.append(i.text.replace('out of 5 stars',''))\n",
    "\n",
    "l1,l2,l3,l4 = [],[],[],[]\n",
    "\n",
    "l1 = [name.text for name in name_block]\n",
    "l2 = [int(price.text.replace(',','')) for price in price_block]\n",
    "l3 = [img_url.img.get('src') for img_url in img_url_block]\n",
    "l4 = [float(rating.text[:3]) for rating in ratings_block[4:]]\n",
    "\n",
    "amazon__under_20k_mobiles_df = pd.DataFrame({'mobile_name':l1,'price':l2,'rating':l4,'image_url':l3})\n",
    "\n",
    "amazon__under_20k_mobiles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to extract information about the local weather from the National \n",
    "#Weather Service website of USA, https://www.weather.gov/ for the city, San \n",
    "#Francisco. You need to extract data about 7 day extended forecast display for the city. \n",
    "#The data should include period, short description, temperature and description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>short_des</th>\n",
       "      <th>temperature</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TodaySunny,</td>\n",
       "      <td>TodaySunny</td>\n",
       "      <td>66</td>\n",
       "      <td>with a high near 66. Light  west southwest win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>Tonight Partly cloudy</td>\n",
       "      <td>50</td>\n",
       "      <td>Partly cloudy, with a low around 50. West sout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Thursday Mostly sunny</td>\n",
       "      <td>63</td>\n",
       "      <td>Mostly sunny, with a high near 63. West wind 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Thursday Night Mostly clear</td>\n",
       "      <td>50</td>\n",
       "      <td>Night Mostly clear, with a low around 50. West...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FridaySunny,</td>\n",
       "      <td>FridaySunny</td>\n",
       "      <td>66</td>\n",
       "      <td>with a high near 66. Light  west southwest win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Friday Night Mostly clear</td>\n",
       "      <td>51</td>\n",
       "      <td>Night Mostly clear, with a low around 51.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Saturday Sunny</td>\n",
       "      <td>72</td>\n",
       "      <td>Sunny, with a high near 72.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Saturday Night Mostly clear</td>\n",
       "      <td>53</td>\n",
       "      <td>Night Mostly clear, with a low around 53.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Sunday Sunny</td>\n",
       "      <td>71</td>\n",
       "      <td>Sunny, with a high near 71.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Sunday Night Clear</td>\n",
       "      <td>53</td>\n",
       "      <td>Night Clear, with a low around 53.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Monday Sunny</td>\n",
       "      <td>74</td>\n",
       "      <td>Sunny, with a high near 74.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Monday Night Mostly clear</td>\n",
       "      <td>51</td>\n",
       "      <td>Night Mostly clear, with a low around 51.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Tuesday Sunny</td>\n",
       "      <td>70</td>\n",
       "      <td>Sunny, with a high near 70.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          period                    short_des  temperature  \\\n",
       "0    TodaySunny,                   TodaySunny           66   \n",
       "1        Tonight        Tonight Partly cloudy           50   \n",
       "2       Thursday        Thursday Mostly sunny           63   \n",
       "3       Thursday  Thursday Night Mostly clear           50   \n",
       "4   FridaySunny,                  FridaySunny           66   \n",
       "5         Friday    Friday Night Mostly clear           51   \n",
       "6       Saturday               Saturday Sunny           72   \n",
       "7       Saturday  Saturday Night Mostly clear           53   \n",
       "8         Sunday                 Sunday Sunny           71   \n",
       "9         Sunday           Sunday Night Clear           53   \n",
       "10        Monday                 Monday Sunny           74   \n",
       "11        Monday    Monday Night Mostly clear           51   \n",
       "12       Tuesday                Tuesday Sunny           70   \n",
       "\n",
       "                                          description  \n",
       "0   with a high near 66. Light  west southwest win...  \n",
       "1   Partly cloudy, with a low around 50. West sout...  \n",
       "2   Mostly sunny, with a high near 63. West wind 8...  \n",
       "3   Night Mostly clear, with a low around 50. West...  \n",
       "4   with a high near 66. Light  west southwest win...  \n",
       "5           Night Mostly clear, with a low around 51.  \n",
       "6                         Sunny, with a high near 72.  \n",
       "7           Night Mostly clear, with a low around 53.  \n",
       "8                         Sunny, with a high near 71.  \n",
       "9                  Night Clear, with a low around 53.  \n",
       "10                        Sunny, with a high near 74.  \n",
       "11          Night Mostly clear, with a low around 51.  \n",
       "12                        Sunny, with a high near 70.  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from lxml import html\n",
    "import re\n",
    "\n",
    "forcastpageContent=requests.get(\n",
    "     'https://forecast.weather.gov/MapClick.php?lat=37.77493000000004&lon=-122.41941999999995#.X7vZI1UzbIU'\n",
    ")\n",
    "\n",
    "tree = html.fromstring(forcastpageContent.content)\n",
    "\n",
    "period = []\n",
    "shrt_des = []\n",
    "temp_f = []\n",
    "des = []\n",
    "\n",
    "for t in tree.xpath(\"//div[contains(@class,'row-forecast')]\"):\n",
    "    \n",
    "    if 'ight' in t.text_content():\n",
    "        temp = t.text_content().replace('ight','ight ')\n",
    "        period.append(temp.split()[0])\n",
    "        shrt_des.append(temp.split(',')[0])\n",
    "        temp_f.append(int(''.join(re.findall('[0-9]',temp))[:2]))\n",
    "        des.append(''.join(temp.split(' ',maxsplit=1)[1:]))\n",
    "        \n",
    "    else:\n",
    "        temp = t.text_content().replace('day','day ')\n",
    "        period.append(temp.split()[0])\n",
    "        shrt_des.append(temp.split(',')[0])\n",
    "        temp_f.append(int(''.join(re.findall('[0-9]',temp))[:2]))\n",
    "        des.append(''.join(temp.split(' ',maxsplit=1)[1:]))\n",
    "        \n",
    "sf_temp_df = pd.DataFrame({'period':period,'short_des':shrt_des,'temperature':temp_f,'description':des})\n",
    "\n",
    "sf_temp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
